{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import baseline\n",
    "from encoder import *\n",
    "from baseline import *\n",
    "from decoder import *\n",
    "from alphabet import *\n",
    "from train import *\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76738 training examples, 9590 validation examples, 9616 test exampless\n"
     ]
    }
   ],
   "source": [
    "LANGUAGE = 'Python'\n",
    "\n",
    "def filter_ascii(strings):\n",
    "    'Returns only the strings that can be encoded in ASCII.'\n",
    "    l = []\n",
    "    for s in strings:\n",
    "        try:\n",
    "            s.encode('ascii')\n",
    "            if len(s) <= 80:\n",
    "                l.append(s)\n",
    "        except UnicodeEncodeError:\n",
    "            pass\n",
    "        \n",
    "    return l\n",
    "\n",
    "with open('dataset/medium.json') as f:\n",
    "    multilang_dataset = json.load(f)\n",
    "    dataset = multilang_dataset[LANGUAGE]\n",
    "    \n",
    "    dataset['train'] = filter_ascii(dataset['train'])\n",
    "    dataset['dev'] = filter_ascii(dataset['dev'])\n",
    "    dataset['test'] = filter_ascii(dataset['test'])\n",
    "    \n",
    "    tiny_dataset = {\n",
    "        'train': dataset['train'][:50],\n",
    "        'dev': dataset['train'][:50],\n",
    "        'test': dataset['train'][:50],\n",
    "    }\n",
    "    \n",
    "    print('{} training examples, {} validation examples, {} test exampless'.format(\n",
    "        len(dataset['train']), \n",
    "        len(dataset['dev']),\n",
    "        len(dataset['test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dumb_dataset():\n",
    "    'Returns a dataset where all examples are the same string, which consists of 10 times the same letter.'\n",
    "\n",
    "    SIZE = 200\n",
    "    l = []\n",
    "\n",
    "    for i in range(SIZE):\n",
    "        l.append(random.choice('abcdefghijklmnopqrstuvwxyz') * random.choice([5, 10]))\n",
    "        \n",
    "    return {'train': l, 'dev': l, 'test': l}\n",
    "\n",
    "dumb_dataset = generate_dumb_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(0) if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "alphabet = AsciiOneHotEncoding(device)\n",
    "encoder = baseline.UniformEncoder(0.9)\n",
    "decoder = AutoCompleteDecoderModel(alphabet, hidden_size=64)\n",
    "nencoder = NeuralEncoder(alphabet, epsilon=0.5, hidden_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-4.81735604984369,\n",
       "  '\\x01\\x02',\n",
       "  tensor([[ 0.0379,  0.0103,  0.0729, -0.0059, -0.0102,  0.0876, -0.0396,  0.0343,\n",
       "            0.0184,  0.0060,  0.0270, -0.0606, -0.0315, -0.0503,  0.0025,  0.0263,\n",
       "            0.0372, -0.0463,  0.0517, -0.0054, -0.0363, -0.0678,  0.0483, -0.0529,\n",
       "           -0.0234, -0.0349,  0.0242, -0.0795,  0.0252,  0.0210, -0.0412,  0.0333,\n",
       "            0.0028, -0.0584, -0.0897,  0.0544, -0.0127,  0.0207,  0.0022, -0.0644,\n",
       "           -0.0258, -0.0074, -0.0080, -0.0492, -0.0103, -0.0111, -0.0155, -0.0705,\n",
       "            0.0363, -0.0040, -0.0352,  0.0498,  0.0075,  0.0207, -0.0178, -0.0362,\n",
       "            0.0475, -0.0749,  0.0150,  0.0410, -0.0380,  0.0149, -0.0382, -0.0475]],\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[ 0.0681,  0.0205,  0.1415, -0.0117, -0.0202,  0.1558, -0.0769,  0.0759,\n",
       "            0.0359,  0.0120,  0.0509, -0.1129, -0.0683, -0.1075,  0.0051,  0.0483,\n",
       "            0.0724, -0.0912,  0.1005, -0.0107, -0.0700, -0.1327,  0.1008, -0.1153,\n",
       "           -0.0454, -0.0672,  0.0449, -0.1500,  0.0481,  0.0431, -0.0757,  0.0773,\n",
       "            0.0057, -0.1222, -0.1620,  0.1008, -0.0257,  0.0402,  0.0045, -0.1427,\n",
       "           -0.0492, -0.0144, -0.0187, -0.1090, -0.0195, -0.0212, -0.0343, -0.1489,\n",
       "            0.0725, -0.0081, -0.0644,  0.0971,  0.0160,  0.0398, -0.0373, -0.0759,\n",
       "            0.0988, -0.1471,  0.0298,  0.0808, -0.0722,  0.0350, -0.0738, -0.0845]],\n",
       "         grad_fn=<AddBackward0>)),\n",
       " (-9.620476244296178,\n",
       "  '\\x01Y\\x02',\n",
       "  tensor([[ 0.0701,  0.0022,  0.0545, -0.0168, -0.0429,  0.1275, -0.0065,  0.0018,\n",
       "            0.0281, -0.0467,  0.0483, -0.0378, -0.0396, -0.0388,  0.0309, -0.0107,\n",
       "            0.0826, -0.0622,  0.0394, -0.0023, -0.0616, -0.0745,  0.0617, -0.0485,\n",
       "           -0.0354, -0.0613,  0.0711, -0.0298,  0.0054,  0.0056, -0.0207,  0.0151,\n",
       "            0.0299, -0.0228, -0.1370,  0.0142, -0.0149,  0.0332,  0.0114, -0.0900,\n",
       "           -0.0765,  0.0183, -0.0144, -0.0252, -0.0477, -0.0211, -0.0469, -0.0756,\n",
       "            0.0501, -0.0445, -0.0213,  0.0392, -0.0056,  0.0440, -0.0283, -0.0334,\n",
       "            0.0187, -0.0973, -0.0099,  0.0417, -0.0391,  0.0363,  0.0060, -0.0678]],\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[ 0.1334,  0.0045,  0.1212, -0.0345, -0.0835,  0.2459, -0.0127,  0.0040,\n",
       "            0.0516, -0.0900,  0.0896, -0.0658, -0.0802, -0.0773,  0.0661, -0.0189,\n",
       "            0.1758, -0.1343,  0.0815, -0.0045, -0.1192, -0.1470,  0.1317, -0.1014,\n",
       "           -0.0688, -0.1267,  0.1233, -0.0623,  0.0099,  0.0110, -0.0391,  0.0338,\n",
       "            0.0582, -0.0477, -0.2691,  0.0279, -0.0278,  0.0652,  0.0231, -0.1902,\n",
       "           -0.1449,  0.0374, -0.0301, -0.0528, -0.0950, -0.0423, -0.1063, -0.1500,\n",
       "            0.1000, -0.0921, -0.0388,  0.0732, -0.0115,  0.0860, -0.0609, -0.0643,\n",
       "            0.0369, -0.1793, -0.0200,  0.0787, -0.0803,  0.0837,  0.0124, -0.1264]],\n",
       "         grad_fn=<AddBackward0>))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.beam_search(\"hello\", alphabet, beam_size=2, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240.10151319598083\n"
     ]
    }
   ],
   "source": [
    "def expected_initial_loss(input_string, epsilon, alphabet, lam):\n",
    "    s, a = len(input_string), alphabet.embedding_size()\n",
    "    return s/2.0 + lam*(s*math.log(a)-epsilon)\n",
    "\n",
    "print(expected_initial_loss('ddddd',0.5,alphabet,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial lambda: 30.0\n",
      "Epoch 0 iteration 0: loss = 29.929, lambda: 30.010, % kept: 1.000, rec_loss: 4.852, enc_ll: -0.04, tp = 6.37 lines/s, ETA 00h01m34s\n",
      "Epoch 0 iteration 2: loss = 399.622, lambda: 30.163, % kept: 0.800, rec_loss: 4.852, enc_ll: -0.54, tp = 13.66 lines/s, ETA 00h00m43s\n",
      "Epoch 0 iteration 4: loss = 30.041, lambda: 30.195, % kept: 1.000, rec_loss: 4.849, enc_ll: -0.04, tp = 17.63 lines/s, ETA 00h00m33s\n",
      "Epoch 0 iteration 6: loss = 30.004, lambda: 30.214, % kept: 1.000, rec_loss: 4.842, enc_ll: -0.04, tp = 21.05 lines/s, ETA 00h00m28s\n",
      "Epoch 0 iteration 8: loss = 459.438, lambda: 30.375, % kept: 0.900, rec_loss: 4.776, enc_ll: -0.32, tp = 22.53 lines/s, ETA 00h00m26s\n",
      "Epoch 0 iteration 10: loss = 431.654, lambda: 30.535, % kept: 0.900, rec_loss: 4.464, enc_ll: -0.32, tp = 22.80 lines/s, ETA 00h00m25s\n",
      "Epoch 0 iteration 12: loss = 64.470, lambda: 30.707, % kept: 1.000, rec_loss: 4.753, enc_ll: -0.04, tp = 23.23 lines/s, ETA 00h00m25s\n",
      "Epoch 0 iteration 14: loss = 671.659, lambda: 31.181, % kept: 0.600, rec_loss: 4.123, enc_ll: -1.04, tp = 24.12 lines/s, ETA 00h00m24s\n",
      "Epoch 0 iteration 16: loss = 71.710, lambda: 31.213, % kept: 1.000, rec_loss: 5.193, enc_ll: -0.04, tp = 24.87 lines/s, ETA 00h00m23s\n",
      "Epoch 0 iteration 18: loss = 21.465, lambda: 31.383, % kept: 1.000, rec_loss: 3.353, enc_ll: -0.04, tp = 25.22 lines/s, ETA 00h00m23s\n",
      "Epoch 0 iteration 20: loss = 59.633, lambda: 31.860, % kept: 1.000, rec_loss: 4.232, enc_ll: -0.04, tp = 24.73 lines/s, ETA 00h00m23s\n",
      "Epoch 0 iteration 22: loss = 511.698, lambda: 32.179, % kept: 0.900, rec_loss: 5.024, enc_ll: -0.32, tp = 24.68 lines/s, ETA 00h00m23s\n",
      "Epoch 0 iteration 24: loss = 30.609, lambda: 32.196, % kept: 1.000, rec_loss: 4.631, enc_ll: -0.04, tp = 25.25 lines/s, ETA 00h00m22s\n",
      "Epoch 0 iteration 26: loss = 68.015, lambda: 32.235, % kept: 1.000, rec_loss: 4.760, enc_ll: -0.04, tp = 25.38 lines/s, ETA 00h00m22s\n",
      "Epoch 0 iteration 28: loss = 30.473, lambda: 32.253, % kept: 1.000, rec_loss: 4.600, enc_ll: -0.04, tp = 25.54 lines/s, ETA 00h00m22s\n",
      "Epoch 0 iteration 30: loss = 31.152, lambda: 32.272, % kept: 1.000, rec_loss: 4.698, enc_ll: -0.04, tp = 26.00 lines/s, ETA 00h00m21s\n",
      "Epoch 0 iteration 32: loss = 348.529, lambda: 32.398, % kept: 0.800, rec_loss: 3.953, enc_ll: -0.54, tp = 26.29 lines/s, ETA 00h00m21s\n",
      "Epoch 0 iteration 34: loss = 30.960, lambda: 32.423, % kept: 1.000, rec_loss: 4.649, enc_ll: -0.04, tp = 26.63 lines/s, ETA 00h00m21s\n",
      "Epoch 0 iteration 36: loss = 68.829, lambda: 32.564, % kept: 1.000, rec_loss: 4.768, enc_ll: -0.04, tp = 26.56 lines/s, ETA 00h00m21s\n",
      "Epoch 0 iteration 38: loss = 378.879, lambda: 32.691, % kept: 0.900, rec_loss: 3.664, enc_ll: -0.32, tp = 26.51 lines/s, ETA 00h00m21s\n",
      "Epoch 0 iteration 40: loss = 43.047, lambda: 32.781, % kept: 1.000, rec_loss: 2.968, enc_ll: -0.04, tp = 26.32 lines/s, ETA 00h00m21s\n",
      "Epoch 0 iteration 42: loss = 380.302, lambda: 32.902, % kept: 0.900, rec_loss: 3.654, enc_ll: -0.32, tp = 26.37 lines/s, ETA 00h00m21s\n",
      "Epoch 0 iteration 44: loss = 42.065, lambda: 32.925, % kept: 1.000, rec_loss: 6.199, enc_ll: -0.04, tp = 26.65 lines/s, ETA 00h00m20s\n",
      "Epoch 0 iteration 46: loss = 100.087, lambda: 33.102, % kept: 1.000, rec_loss: 6.812, enc_ll: -0.04, tp = 26.62 lines/s, ETA 00h00m20s\n",
      "Epoch 0 iteration 48: loss = 38.941, lambda: 33.124, % kept: 1.000, rec_loss: 2.660, enc_ll: -0.04, tp = 26.67 lines/s, ETA 00h00m20s\n",
      "Epoch 0 iteration 50: loss = 19.709, lambda: 33.156, % kept: 1.000, rec_loss: 2.918, enc_ll: -0.04, tp = 26.78 lines/s, ETA 00h00m20s\n",
      "Epoch 0 iteration 52: loss = 407.173, lambda: 33.287, % kept: 0.800, rec_loss: 4.486, enc_ll: -0.54, tp = 27.01 lines/s, ETA 00h00m20s\n",
      "Epoch 0 iteration 54: loss = 42.181, lambda: 33.415, % kept: 1.000, rec_loss: 6.130, enc_ll: -0.04, tp = 27.28 lines/s, ETA 00h00m19s\n",
      "Epoch 0 iteration 56: loss = 571.090, lambda: 33.795, % kept: 0.900, rec_loss: 5.339, enc_ll: -0.32, tp = 27.20 lines/s, ETA 00h00m19s\n",
      "Epoch 0 iteration 58: loss = 33.037, lambda: 33.815, % kept: 1.000, rec_loss: 4.758, enc_ll: -0.04, tp = 27.32 lines/s, ETA 00h00m19s\n",
      "Epoch 0 iteration 60: loss = 49.764, lambda: 33.841, % kept: 1.000, rec_loss: 3.324, enc_ll: -0.04, tp = 27.42 lines/s, ETA 00h00m19s\n",
      "Epoch 0 iteration 62: loss = 22.053, lambda: 33.875, % kept: 1.000, rec_loss: 3.192, enc_ll: -0.04, tp = 27.49 lines/s, ETA 00h00m19s\n",
      "Epoch 0 iteration 64: loss = 46.909, lambda: 34.069, % kept: 1.000, rec_loss: 3.113, enc_ll: -0.04, tp = 27.49 lines/s, ETA 00h00m19s\n",
      "Epoch 0 iteration 66: loss = 392.091, lambda: 34.211, % kept: 0.900, rec_loss: 3.624, enc_ll: -0.32, tp = 27.46 lines/s, ETA 00h00m19s\n",
      "Epoch 0 iteration 68: loss = 23.437, lambda: 34.227, % kept: 1.000, rec_loss: 3.355, enc_ll: -0.04, tp = 27.61 lines/s, ETA 00h00m19s\n",
      "Epoch 0 iteration 70: loss = 75.618, lambda: 34.518, % kept: 1.000, rec_loss: 4.946, enc_ll: -0.04, tp = 27.56 lines/s, ETA 00h00m19s\n",
      "Epoch 0 iteration 72: loss = 19.832, lambda: 34.537, % kept: 1.000, rec_loss: 2.825, enc_ll: -0.04, tp = 27.64 lines/s, ETA 00h00m19s\n",
      "Epoch 0 iteration 74: loss = 23.233, lambda: 34.554, % kept: 1.000, rec_loss: 3.296, enc_ll: -0.04, tp = 27.82 lines/s, ETA 00h00m18s\n",
      "Epoch 0 iteration 76: loss = 383.348, lambda: 34.674, % kept: 0.800, rec_loss: 4.061, enc_ll: -0.54, tp = 27.97 lines/s, ETA 00h00m18s\n",
      "Epoch 0 iteration 78: loss = 296.297, lambda: 34.770, % kept: 0.800, rec_loss: 3.144, enc_ll: -0.54, tp = 27.96 lines/s, ETA 00h00m18s\n",
      "Epoch 0 iteration 80: loss = 35.569, lambda: 34.808, % kept: 1.000, rec_loss: 2.319, enc_ll: -0.04, tp = 27.95 lines/s, ETA 00h00m18s\n",
      "Epoch 0 iteration 82: loss = 47.898, lambda: 34.837, % kept: 1.000, rec_loss: 3.113, enc_ll: -0.04, tp = 27.89 lines/s, ETA 00h00m18s\n",
      "Epoch 0 iteration 84: loss = 530.177, lambda: 34.995, % kept: 0.900, rec_loss: 4.787, enc_ll: -0.32, tp = 27.98 lines/s, ETA 00h00m18s\n",
      "Epoch 0 iteration 86: loss = 29.665, lambda: 35.011, % kept: 1.000, rec_loss: 4.141, enc_ll: -0.04, tp = 28.14 lines/s, ETA 00h00m18s\n",
      "Epoch 0 iteration 88: loss = 74.548, lambda: 35.048, % kept: 1.000, rec_loss: 4.807, enc_ll: -0.04, tp = 28.12 lines/s, ETA 00h00m18s\n",
      "Epoch 0 iteration 90: loss = 1024.007, lambda: 35.349, % kept: 0.800, rec_loss: 4.939, enc_ll: -0.59, tp = 28.11 lines/s, ETA 00h00m18s\n",
      "Epoch 0 iteration 92: loss = 59.783, lambda: 35.370, % kept: 1.000, rec_loss: 3.826, enc_ll: -0.04, tp = 28.14 lines/s, ETA 00h00m18s\n",
      "Epoch 0 iteration 94: loss = 27.825, lambda: 35.384, % kept: 1.000, rec_loss: 3.851, enc_ll: -0.04, tp = 28.30 lines/s, ETA 00h00m17s\n",
      "Epoch 0 iteration 96: loss = 64.377, lambda: 35.407, % kept: 1.000, rec_loss: 4.114, enc_ll: -0.04, tp = 28.37 lines/s, ETA 00h00m17s\n",
      "Epoch 0 iteration 98: loss = 305.125, lambda: 35.503, % kept: 0.900, rec_loss: 2.722, enc_ll: -0.32, tp = 28.32 lines/s, ETA 00h00m17s\n",
      "Epoch 0 iteration 100: loss = 450.140, lambda: 35.777, % kept: 0.900, rec_loss: 3.977, enc_ll: -0.32, tp = 28.19 lines/s, ETA 00h00m17s\n",
      "Epoch 0 iteration 102: loss = 39.603, lambda: 35.854, % kept: 1.000, rec_loss: 5.383, enc_ll: -0.04, tp = 28.32 lines/s, ETA 00h00m17s\n",
      "Epoch 0 iteration 104: loss = 794.364, lambda: 36.088, % kept: 0.900, rec_loss: 6.956, enc_ll: -0.32, tp = 28.22 lines/s, ETA 00h00m17s\n",
      "Epoch 0 iteration 106: loss = 95.878, lambda: 36.128, % kept: 1.000, rec_loss: 5.997, enc_ll: -0.04, tp = 28.20 lines/s, ETA 00h00m17s\n",
      "Epoch 0 iteration 108: loss = 87.838, lambda: 36.163, % kept: 1.000, rec_loss: 5.492, enc_ll: -0.04, tp = 28.20 lines/s, ETA 00h00m17s\n",
      "Epoch 0 iteration 110: loss = 329.463, lambda: 36.277, % kept: 0.800, rec_loss: 3.346, enc_ll: -0.54, tp = 28.23 lines/s, ETA 00h00m17s\n",
      "Epoch 0 iteration 112: loss = 311.378, lambda: 36.370, % kept: 0.800, rec_loss: 3.158, enc_ll: -0.54, tp = 28.38 lines/s, ETA 00h00m17s\n",
      "Epoch 0 iteration 114: loss = 375.792, lambda: 36.482, % kept: 0.800, rec_loss: 3.787, enc_ll: -0.54, tp = 28.47 lines/s, ETA 00h00m17s\n",
      "Epoch 0 iteration 116: loss = 32.867, lambda: 36.599, % kept: 1.000, rec_loss: 2.046, enc_ll: -0.04, tp = 28.54 lines/s, ETA 00h00m16s\n",
      "Epoch 0 iteration 118: loss = 39.918, lambda: 36.629, % kept: 1.000, rec_loss: 2.477, enc_ll: -0.04, tp = 28.47 lines/s, ETA 00h00m16s\n",
      "Epoch 0 iteration 120: loss = 24.058, lambda: 36.645, % kept: 1.000, rec_loss: 3.228, enc_ll: -0.04, tp = 28.57 lines/s, ETA 00h00m16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 iteration 122: loss = 18.329, lambda: 36.781, % kept: 1.000, rec_loss: 2.466, enc_ll: -0.04, tp = 28.61 lines/s, ETA 00h00m16s\n",
      "Epoch 0 iteration 124: loss = 38.941, lambda: 36.893, % kept: 1.000, rec_loss: 2.401, enc_ll: -0.04, tp = 28.60 lines/s, ETA 00h00m16s\n",
      "Epoch 0 iteration 126: loss = 500.469, lambda: 37.169, % kept: 0.900, rec_loss: 4.255, enc_ll: -0.32, tp = 28.56 lines/s, ETA 00h00m16s\n",
      "Epoch 0 iteration 128: loss = 41.266, lambda: 37.188, % kept: 1.000, rec_loss: 2.523, enc_ll: -0.04, tp = 28.61 lines/s, ETA 00h00m16s\n",
      "Epoch 0 iteration 130: loss = 777.465, lambda: 37.402, % kept: 0.800, rec_loss: 3.544, enc_ll: -0.59, tp = 28.65 lines/s, ETA 00h00m16s\n",
      "Epoch 0 iteration 132: loss = 21.414, lambda: 37.514, % kept: 1.000, rec_loss: 2.814, enc_ll: -0.04, tp = 28.68 lines/s, ETA 00h00m16s\n",
      "Epoch 0 iteration 134: loss = 316.493, lambda: 37.717, % kept: 0.800, rec_loss: 3.098, enc_ll: -0.54, tp = 28.70 lines/s, ETA 00h00m16s\n",
      "Epoch 0 iteration 136: loss = 31.316, lambda: 37.820, % kept: 1.000, rec_loss: 4.049, enc_ll: -0.04, tp = 28.78 lines/s, ETA 00h00m16s\n",
      "Epoch 0 iteration 138: loss = 399.694, lambda: 38.183, % kept: 0.800, rec_loss: 3.849, enc_ll: -0.54, tp = 28.79 lines/s, ETA 00h00m16s\n",
      "Epoch 0 iteration 140: loss = 32.824, lambda: 38.273, % kept: 1.000, rec_loss: 4.189, enc_ll: -0.04, tp = 28.89 lines/s, ETA 00h00m15s\n",
      "Epoch 0 iteration 142: loss = 59.219, lambda: 38.307, % kept: 1.000, rec_loss: 3.493, enc_ll: -0.04, tp = 28.85 lines/s, ETA 00h00m15s\n",
      "Epoch 0 iteration 144: loss = 77.301, lambda: 38.424, % kept: 1.000, rec_loss: 4.539, enc_ll: -0.04, tp = 28.90 lines/s, ETA 00h00m15s\n",
      "Epoch 0 iteration 146: loss = 47.554, lambda: 38.452, % kept: 1.000, rec_loss: 2.797, enc_ll: -0.04, tp = 28.89 lines/s, ETA 00h00m15s\n",
      "Epoch 0 iteration 148: loss = 58.034, lambda: 38.595, % kept: 1.000, rec_loss: 3.395, enc_ll: -0.04, tp = 28.87 lines/s, ETA 00h00m15s\n",
      "Epoch 0 iteration 150: loss = 32.488, lambda: 38.620, % kept: 1.000, rec_loss: 4.101, enc_ll: -0.04, tp = 28.90 lines/s, ETA 00h00m15s\n",
      "Epoch 0 iteration 152: loss = 924.287, lambda: 38.868, % kept: 0.900, rec_loss: 7.520, enc_ll: -0.32, tp = 28.91 lines/s, ETA 00h00m15s\n",
      "Epoch 0 iteration 154: loss = 64.629, lambda: 38.910, % kept: 1.000, rec_loss: 3.748, enc_ll: -0.04, tp = 28.90 lines/s, ETA 00h00m15s\n",
      "Epoch 0 iteration 156: loss = 470.251, lambda: 39.214, % kept: 0.900, rec_loss: 3.795, enc_ll: -0.32, tp = 28.88 lines/s, ETA 00h00m15s\n",
      "Epoch 0 iteration 158: loss = 743.294, lambda: 39.531, % kept: 0.900, rec_loss: 5.944, enc_ll: -0.32, tp = 28.85 lines/s, ETA 00h00m15s\n",
      "Epoch 0 iteration 160: loss = 57.485, lambda: 39.552, % kept: 1.000, rec_loss: 3.281, enc_ll: -0.04, tp = 28.85 lines/s, ETA 00h00m15s\n",
      "Epoch 0 iteration 162: loss = 391.405, lambda: 39.751, % kept: 0.900, rec_loss: 3.120, enc_ll: -0.32, tp = 28.84 lines/s, ETA 00h00m15s\n",
      "Epoch 0 iteration 164: loss = 65.503, lambda: 39.775, % kept: 1.000, rec_loss: 3.713, enc_ll: -0.04, tp = 28.87 lines/s, ETA 00h00m15s\n",
      "Epoch 0 iteration 166: loss = 527.237, lambda: 39.914, % kept: 0.800, rec_loss: 4.846, enc_ll: -0.54, tp = 28.97 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 168: loss = 29.460, lambda: 39.938, % kept: 1.000, rec_loss: 3.601, enc_ll: -0.04, tp = 28.98 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 170: loss = 442.945, lambda: 40.057, % kept: 0.900, rec_loss: 3.502, enc_ll: -0.32, tp = 29.00 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 172: loss = 32.796, lambda: 40.080, % kept: 1.000, rec_loss: 3.987, enc_ll: -0.04, tp = 29.00 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 174: loss = 816.298, lambda: 40.395, % kept: 0.800, rec_loss: 3.451, enc_ll: -0.59, tp = 28.93 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 176: loss = 45.650, lambda: 40.413, % kept: 1.000, rec_loss: 2.553, enc_ll: -0.04, tp = 28.90 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 178: loss = 59.849, lambda: 40.434, % kept: 1.000, rec_loss: 3.337, enc_ll: -0.04, tp = 28.91 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 180: loss = 27.568, lambda: 40.449, % kept: 1.000, rec_loss: 3.331, enc_ll: -0.04, tp = 28.96 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 182: loss = 596.208, lambda: 40.606, % kept: 0.900, rec_loss: 4.644, enc_ll: -0.32, tp = 28.96 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 184: loss = 284.184, lambda: 40.692, % kept: 0.800, rec_loss: 2.595, enc_ll: -0.54, tp = 28.98 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 186: loss = 415.903, lambda: 40.803, % kept: 0.800, rec_loss: 3.755, enc_ll: -0.54, tp = 29.06 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 188: loss = 551.918, lambda: 41.005, % kept: 0.800, rec_loss: 4.938, enc_ll: -0.54, tp = 29.09 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 190: loss = 29.704, lambda: 41.020, % kept: 1.000, rec_loss: 3.536, enc_ll: -0.04, tp = 29.15 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 192: loss = 50.415, lambda: 41.040, % kept: 1.000, rec_loss: 2.775, enc_ll: -0.04, tp = 29.12 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 194: loss = 53.988, lambda: 41.170, % kept: 1.000, rec_loss: 2.958, enc_ll: -0.04, tp = 29.09 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 196: loss = 31.854, lambda: 41.188, % kept: 1.000, rec_loss: 3.769, enc_ll: -0.04, tp = 29.16 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 198: loss = 370.592, lambda: 41.294, % kept: 0.800, rec_loss: 3.315, enc_ll: -0.54, tp = 29.13 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 200: loss = 67.769, lambda: 41.317, % kept: 1.000, rec_loss: 3.697, enc_ll: -0.04, tp = 29.14 lines/s, ETA 00h00m13s\n",
      "Epoch 1 iteration 1: loss = 403.906, lambda: 41.419, % kept: 0.800, rec_loss: 3.596, enc_ll: -0.54, tp = 29.19 lines/s, ETA 00h00m13s\n",
      "Epoch 1 iteration 3: loss = 30.725, lambda: 41.433, % kept: 1.000, rec_loss: 3.621, enc_ll: -0.04, tp = 29.27 lines/s, ETA 00h00m13s\n",
      "Epoch 1 iteration 5: loss = 30.453, lambda: 41.447, % kept: 1.000, rec_loss: 3.589, enc_ll: -0.04, tp = 29.33 lines/s, ETA 00h00m13s\n",
      "Epoch 1 iteration 7: loss = 24.698, lambda: 41.468, % kept: 1.000, rec_loss: 2.922, enc_ll: -0.04, tp = 29.35 lines/s, ETA 00h00m13s\n",
      "Epoch 1 iteration 9: loss = 30.110, lambda: 41.570, % kept: 1.000, rec_loss: 3.539, enc_ll: -0.04, tp = 29.40 lines/s, ETA 00h00m13s\n",
      "Epoch 1 iteration 11: loss = 73.259, lambda: 41.705, % kept: 1.000, rec_loss: 3.960, enc_ll: -0.04, tp = 29.34 lines/s, ETA 00h00m13s\n",
      "Epoch 1 iteration 13: loss = 508.045, lambda: 41.832, % kept: 0.900, rec_loss: 3.844, enc_ll: -0.32, tp = 29.35 lines/s, ETA 00h00m13s\n",
      "Epoch 1 iteration 15: loss = 26.253, lambda: 41.844, % kept: 1.000, rec_loss: 3.075, enc_ll: -0.04, tp = 29.42 lines/s, ETA 00h00m13s\n",
      "Epoch 1 iteration 17: loss = 407.371, lambda: 41.955, % kept: 0.900, rec_loss: 3.078, enc_ll: -0.32, tp = 29.39 lines/s, ETA 00h00m12s\n",
      "Epoch 1 iteration 19: loss = 551.190, lambda: 42.092, % kept: 0.900, rec_loss: 4.144, enc_ll: -0.32, tp = 29.40 lines/s, ETA 00h00m12s\n",
      "Epoch 1 iteration 21: loss = 24.121, lambda: 42.125, % kept: 1.000, rec_loss: 2.813, enc_ll: -0.04, tp = 29.42 lines/s, ETA 00h00m12s\n",
      "Epoch 1 iteration 23: loss = 56.294, lambda: 42.146, % kept: 1.000, rec_loss: 3.020, enc_ll: -0.04, tp = 29.44 lines/s, ETA 00h00m12s\n",
      "Epoch 1 iteration 25: loss = 55.262, lambda: 42.293, % kept: 1.000, rec_loss: 2.956, enc_ll: -0.04, tp = 29.41 lines/s, ETA 00h00m12s\n",
      "Epoch 1 iteration 27: loss = 23.253, lambda: 42.310, % kept: 1.000, rec_loss: 2.706, enc_ll: -0.04, tp = 29.42 lines/s, ETA 00h00m12s\n",
      "Epoch 1 iteration 29: loss = 31.100, lambda: 42.324, % kept: 1.000, rec_loss: 3.594, enc_ll: -0.04, tp = 29.47 lines/s, ETA 00h00m12s\n",
      "Epoch 1 iteration 31: loss = 377.599, lambda: 42.420, % kept: 0.900, rec_loss: 2.823, enc_ll: -0.32, tp = 29.51 lines/s, ETA 00h00m12s\n",
      "Epoch 1 iteration 33: loss = 382.782, lambda: 42.521, % kept: 0.900, rec_loss: 2.855, enc_ll: -0.32, tp = 29.46 lines/s, ETA 00h00m12s\n",
      "Epoch 1 iteration 35: loss = 30.514, lambda: 42.533, % kept: 1.000, rec_loss: 3.513, enc_ll: -0.04, tp = 29.51 lines/s, ETA 00h00m12s\n",
      "Epoch 1 iteration 37: loss = 458.038, lambda: 42.645, % kept: 0.800, rec_loss: 3.951, enc_ll: -0.54, tp = 29.56 lines/s, ETA 00h00m12s\n",
      "Epoch 1 iteration 39: loss = 70.338, lambda: 42.665, % kept: 1.000, rec_loss: 3.728, enc_ll: -0.04, tp = 29.57 lines/s, ETA 00h00m12s\n",
      "Epoch 1 iteration 41: loss = 67.511, lambda: 42.697, % kept: 1.000, rec_loss: 3.576, enc_ll: -0.04, tp = 29.52 lines/s, ETA 00h00m12s\n",
      "Epoch 1 iteration 43: loss = 63.127, lambda: 42.722, % kept: 1.000, rec_loss: 3.346, enc_ll: -0.04, tp = 29.49 lines/s, ETA 00h00m12s\n",
      "Epoch 1 iteration 45: loss = 510.332, lambda: 42.846, % kept: 0.900, rec_loss: 3.769, enc_ll: -0.32, tp = 29.48 lines/s, ETA 00h00m11s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 iteration 47: loss = 437.982, lambda: 43.075, % kept: 0.900, rec_loss: 3.221, enc_ll: -0.32, tp = 29.46 lines/s, ETA 00h00m11s\n",
      "Epoch 1 iteration 49: loss = 39.784, lambda: 43.166, % kept: 1.000, rec_loss: 4.498, enc_ll: -0.04, tp = 29.51 lines/s, ETA 00h00m11s\n",
      "Epoch 1 iteration 51: loss = 55.314, lambda: 43.199, % kept: 1.000, rec_loss: 2.904, enc_ll: -0.04, tp = 29.51 lines/s, ETA 00h00m11s\n",
      "Epoch 1 iteration 53: loss = 28.582, lambda: 43.279, % kept: 1.000, rec_loss: 3.245, enc_ll: -0.04, tp = 29.54 lines/s, ETA 00h00m11s\n",
      "Epoch 1 iteration 55: loss = 272.649, lambda: 43.421, % kept: 0.900, rec_loss: 1.999, enc_ll: -0.32, tp = 29.50 lines/s, ETA 00h00m11s\n",
      "Epoch 1 iteration 57: loss = 40.475, lambda: 43.440, % kept: 1.000, rec_loss: 4.548, enc_ll: -0.04, tp = 29.53 lines/s, ETA 00h00m11s\n",
      "Epoch 1 iteration 59: loss = 42.506, lambda: 43.458, % kept: 1.000, rec_loss: 4.769, enc_ll: -0.04, tp = 29.48 lines/s, ETA 00h00m11s\n",
      "Epoch 1 iteration 61: loss = 58.304, lambda: 43.479, % kept: 1.000, rec_loss: 3.041, enc_ll: -0.04, tp = 29.44 lines/s, ETA 00h00m11s\n",
      "Epoch 1 iteration 63: loss = 29.534, lambda: 43.503, % kept: 1.000, rec_loss: 3.334, enc_ll: -0.04, tp = 29.44 lines/s, ETA 00h00m11s\n",
      "Epoch 1 iteration 65: loss = 86.282, lambda: 43.626, % kept: 1.000, rec_loss: 4.481, enc_ll: -0.04, tp = 29.40 lines/s, ETA 00h00m11s\n",
      "Epoch 1 iteration 67: loss = 30.034, lambda: 43.748, % kept: 1.000, rec_loss: 3.374, enc_ll: -0.04, tp = 29.39 lines/s, ETA 00h00m11s\n",
      "Epoch 1 iteration 69: loss = 32.917, lambda: 43.758, % kept: 1.000, rec_loss: 3.692, enc_ll: -0.04, tp = 29.43 lines/s, ETA 00h00m11s\n",
      "Epoch 1 iteration 71: loss = 66.457, lambda: 43.784, % kept: 1.000, rec_loss: 3.446, enc_ll: -0.04, tp = 29.39 lines/s, ETA 00h00m11s\n",
      "Epoch 1 iteration 73: loss = 13.605, lambda: 43.834, % kept: 1.000, rec_loss: 1.567, enc_ll: -0.04, tp = 29.38 lines/s, ETA 00h00m11s\n",
      "Epoch 1 iteration 75: loss = 435.133, lambda: 43.947, % kept: 0.800, rec_loss: 3.644, enc_ll: -0.54, tp = 29.38 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 77: loss = 40.869, lambda: 44.128, % kept: 1.000, rec_loss: 4.532, enc_ll: -0.04, tp = 29.42 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 79: loss = 79.806, lambda: 44.152, % kept: 1.000, rec_loss: 4.103, enc_ll: -0.04, tp = 29.42 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 81: loss = 66.062, lambda: 44.182, % kept: 1.000, rec_loss: 3.399, enc_ll: -0.04, tp = 29.40 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 83: loss = 30.147, lambda: 44.197, % kept: 1.000, rec_loss: 3.361, enc_ll: -0.04, tp = 29.46 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 85: loss = 33.573, lambda: 44.207, % kept: 1.000, rec_loss: 1.741, enc_ll: -0.04, tp = 29.48 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 87: loss = 91.347, lambda: 44.300, % kept: 1.000, rec_loss: 4.679, enc_ll: -0.04, tp = 29.46 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 89: loss = 95.412, lambda: 44.375, % kept: 1.000, rec_loss: 4.890, enc_ll: -0.04, tp = 29.42 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 91: loss = 28.808, lambda: 44.403, % kept: 1.000, rec_loss: 3.206, enc_ll: -0.04, tp = 29.42 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 93: loss = 618.608, lambda: 44.662, % kept: 0.800, rec_loss: 5.066, enc_ll: -0.54, tp = 29.43 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 95: loss = 223.985, lambda: 44.757, % kept: 0.800, rec_loss: 1.878, enc_ll: -0.54, tp = 29.47 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 97: loss = 537.156, lambda: 44.904, % kept: 0.900, rec_loss: 3.781, enc_ll: -0.32, tp = 29.44 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 99: loss = 43.902, lambda: 44.926, % kept: 1.000, rec_loss: 4.797, enc_ll: -0.04, tp = 29.47 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 101: loss = 92.988, lambda: 45.241, % kept: 1.000, rec_loss: 4.672, enc_ll: -0.04, tp = 29.44 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 103: loss = 17.046, lambda: 45.365, % kept: 1.000, rec_loss: 1.886, enc_ll: -0.04, tp = 29.46 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 105: loss = 39.705, lambda: 45.384, % kept: 1.000, rec_loss: 4.295, enc_ll: -0.04, tp = 29.46 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 107: loss = 566.719, lambda: 45.513, % kept: 0.900, rec_loss: 3.937, enc_ll: -0.32, tp = 29.46 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 109: loss = 31.677, lambda: 45.527, % kept: 1.000, rec_loss: 3.426, enc_ll: -0.04, tp = 29.49 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 111: loss = 66.655, lambda: 45.651, % kept: 1.000, rec_loss: 3.324, enc_ll: -0.04, tp = 29.45 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 113: loss = 429.958, lambda: 45.749, % kept: 0.800, rec_loss: 3.463, enc_ll: -0.54, tp = 29.49 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 115: loss = 387.685, lambda: 45.940, % kept: 0.800, rec_loss: 3.117, enc_ll: -0.54, tp = 29.51 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 117: loss = 88.026, lambda: 45.965, % kept: 1.000, rec_loss: 4.342, enc_ll: -0.04, tp = 29.53 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 119: loss = 26.861, lambda: 46.067, % kept: 1.000, rec_loss: 2.881, enc_ll: -0.04, tp = 29.54 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 121: loss = 36.364, lambda: 46.177, % kept: 1.000, rec_loss: 3.865, enc_ll: -0.04, tp = 29.54 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 123: loss = 85.199, lambda: 46.286, % kept: 1.000, rec_loss: 4.172, enc_ll: -0.04, tp = 29.53 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 125: loss = 358.291, lambda: 46.375, % kept: 0.900, rec_loss: 2.454, enc_ll: -0.32, tp = 29.50 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 127: loss = 44.807, lambda: 46.391, % kept: 1.000, rec_loss: 2.202, enc_ll: -0.04, tp = 29.51 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 129: loss = 38.112, lambda: 46.411, % kept: 1.000, rec_loss: 4.027, enc_ll: -0.04, tp = 29.50 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 131: loss = 42.984, lambda: 46.489, % kept: 1.000, rec_loss: 4.523, enc_ll: -0.04, tp = 29.54 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 133: loss = 486.789, lambda: 46.650, % kept: 0.900, rec_loss: 3.304, enc_ll: -0.32, tp = 29.55 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 135: loss = 53.064, lambda: 46.670, % kept: 1.000, rec_loss: 2.589, enc_ll: -0.04, tp = 29.55 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 137: loss = 17.470, lambda: 46.692, % kept: 1.000, rec_loss: 1.874, enc_ll: -0.04, tp = 29.56 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 139: loss = 36.599, lambda: 46.718, % kept: 1.000, rec_loss: 1.793, enc_ll: -0.04, tp = 29.54 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 141: loss = 17.436, lambda: 46.741, % kept: 1.000, rec_loss: 1.869, enc_ll: -0.04, tp = 29.55 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 143: loss = 42.243, lambda: 46.768, % kept: 1.000, rec_loss: 4.428, enc_ll: -0.04, tp = 29.54 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 145: loss = 1013.806, lambda: 46.990, % kept: 0.800, rec_loss: 3.677, enc_ll: -0.59, tp = 29.56 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 147: loss = 22.578, lambda: 47.011, % kept: 1.000, rec_loss: 2.393, enc_ll: -0.04, tp = 29.56 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 149: loss = 610.144, lambda: 47.148, % kept: 0.900, rec_loss: 4.091, enc_ll: -0.32, tp = 29.56 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 151: loss = 24.333, lambda: 47.206, % kept: 1.000, rec_loss: 2.563, enc_ll: -0.04, tp = 29.55 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 153: loss = 435.484, lambda: 47.393, % kept: 0.900, rec_loss: 2.913, enc_ll: -0.32, tp = 29.52 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 155: loss = 457.638, lambda: 47.556, % kept: 0.800, rec_loss: 3.544, enc_ll: -0.54, tp = 29.54 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 157: loss = 372.885, lambda: 47.777, % kept: 0.900, rec_loss: 2.479, enc_ll: -0.32, tp = 29.51 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 159: loss = 22.740, lambda: 47.891, % kept: 1.000, rec_loss: 2.360, enc_ll: -0.04, tp = 29.55 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 161: loss = 35.809, lambda: 47.973, % kept: 1.000, rec_loss: 3.667, enc_ll: -0.04, tp = 29.59 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 163: loss = 39.726, lambda: 48.096, % kept: 1.000, rec_loss: 1.886, enc_ll: -0.04, tp = 29.57 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 165: loss = 71.459, lambda: 48.210, % kept: 1.000, rec_loss: 3.359, enc_ll: -0.04, tp = 29.55 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 167: loss = 45.694, lambda: 48.354, % kept: 1.000, rec_loss: 2.152, enc_ll: -0.04, tp = 29.52 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 169: loss = 36.612, lambda: 48.450, % kept: 1.000, rec_loss: 1.725, enc_ll: -0.04, tp = 29.52 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 171: loss = 35.115, lambda: 48.464, % kept: 1.000, rec_loss: 1.655, enc_ll: -0.04, tp = 29.51 lines/s, ETA 00h00m07s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 iteration 173: loss = 57.223, lambda: 48.591, % kept: 1.000, rec_loss: 2.671, enc_ll: -0.04, tp = 29.46 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 175: loss = 87.601, lambda: 48.738, % kept: 1.000, rec_loss: 4.061, enc_ll: -0.04, tp = 29.43 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 177: loss = 425.125, lambda: 48.925, % kept: 0.900, rec_loss: 2.760, enc_ll: -0.32, tp = 29.40 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 179: loss = 26.469, lambda: 48.938, % kept: 1.000, rec_loss: 2.665, enc_ll: -0.04, tp = 29.44 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 181: loss = 73.515, lambda: 49.054, % kept: 1.000, rec_loss: 3.388, enc_ll: -0.04, tp = 29.43 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 183: loss = 457.195, lambda: 49.151, % kept: 0.800, rec_loss: 3.435, enc_ll: -0.54, tp = 29.46 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 185: loss = 326.578, lambda: 49.223, % kept: 0.800, rec_loss: 2.472, enc_ll: -0.54, tp = 29.50 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 187: loss = 79.953, lambda: 49.251, % kept: 1.000, rec_loss: 3.665, enc_ll: -0.04, tp = 29.49 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 189: loss = 33.612, lambda: 49.264, % kept: 1.000, rec_loss: 1.557, enc_ll: -0.04, tp = 29.48 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 191: loss = 25.746, lambda: 49.277, % kept: 1.000, rec_loss: 2.576, enc_ll: -0.04, tp = 29.51 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 193: loss = 495.322, lambda: 49.385, % kept: 0.900, rec_loss: 3.181, enc_ll: -0.32, tp = 29.51 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 195: loss = 17.527, lambda: 49.404, % kept: 1.000, rec_loss: 1.773, enc_ll: -0.04, tp = 29.51 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 197: loss = 79.288, lambda: 49.434, % kept: 1.000, rec_loss: 3.627, enc_ll: -0.04, tp = 29.50 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 199: loss = 24.604, lambda: 49.448, % kept: 1.000, rec_loss: 2.458, enc_ll: -0.04, tp = 29.51 lines/s, ETA 00h00m06s\n",
      "Epoch 2 iteration 0: loss = 30.950, lambda: 49.534, % kept: 1.000, rec_loss: 3.066, enc_ll: -0.04, tp = 29.50 lines/s, ETA 00h00m06s\n",
      "Epoch 2 iteration 2: loss = 29.949, lambda: 49.548, % kept: 1.000, rec_loss: 2.974, enc_ll: -0.04, tp = 29.52 lines/s, ETA 00h00m06s\n",
      "Epoch 2 iteration 4: loss = 57.600, lambda: 49.565, % kept: 1.000, rec_loss: 2.636, enc_ll: -0.04, tp = 29.52 lines/s, ETA 00h00m06s\n",
      "Epoch 2 iteration 6: loss = 28.175, lambda: 49.669, % kept: 1.000, rec_loss: 2.801, enc_ll: -0.04, tp = 29.52 lines/s, ETA 00h00m06s\n",
      "Epoch 2 iteration 8: loss = 69.099, lambda: 49.741, % kept: 1.000, rec_loss: 3.150, enc_ll: -0.04, tp = 29.49 lines/s, ETA 00h00m06s\n",
      "Epoch 2 iteration 10: loss = 28.613, lambda: 49.751, % kept: 1.000, rec_loss: 2.837, enc_ll: -0.04, tp = 29.52 lines/s, ETA 00h00m06s\n",
      "Epoch 2 iteration 12: loss = 58.761, lambda: 49.773, % kept: 1.000, rec_loss: 2.682, enc_ll: -0.04, tp = 29.50 lines/s, ETA 00h00m06s\n",
      "Epoch 2 iteration 14: loss = 22.581, lambda: 49.784, % kept: 1.000, rec_loss: 2.256, enc_ll: -0.04, tp = 29.52 lines/s, ETA 00h00m06s\n",
      "Epoch 2 iteration 16: loss = 286.150, lambda: 49.858, % kept: 0.900, rec_loss: 1.833, enc_ll: -0.32, tp = 29.50 lines/s, ETA 00h00m06s\n",
      "Epoch 2 iteration 18: loss = 76.961, lambda: 49.964, % kept: 1.000, rec_loss: 3.497, enc_ll: -0.04, tp = 29.46 lines/s, ETA 00h00m06s\n",
      "Epoch 2 iteration 20: loss = 362.235, lambda: 50.047, % kept: 0.800, rec_loss: 2.687, enc_ll: -0.54, tp = 29.46 lines/s, ETA 00h00m06s\n",
      "Epoch 2 iteration 22: loss = 322.700, lambda: 50.115, % kept: 0.900, rec_loss: 2.052, enc_ll: -0.32, tp = 29.46 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 24: loss = 553.011, lambda: 50.243, % kept: 0.800, rec_loss: 1.891, enc_ll: -0.59, tp = 29.44 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 26: loss = 1277.101, lambda: 50.515, % kept: 0.800, rec_loss: 4.308, enc_ll: -0.59, tp = 29.42 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 28: loss = 31.004, lambda: 50.631, % kept: 1.000, rec_loss: 3.022, enc_ll: -0.04, tp = 29.45 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 30: loss = 28.778, lambda: 50.656, % kept: 1.000, rec_loss: 1.310, enc_ll: -0.04, tp = 29.44 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 32: loss = 61.921, lambda: 50.675, % kept: 1.000, rec_loss: 2.780, enc_ll: -0.04, tp = 29.43 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 34: loss = 25.061, lambda: 50.693, % kept: 1.000, rec_loss: 2.454, enc_ll: -0.04, tp = 29.45 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 36: loss = 72.670, lambda: 50.711, % kept: 1.000, rec_loss: 3.253, enc_ll: -0.04, tp = 29.43 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 38: loss = 69.861, lambda: 50.730, % kept: 1.000, rec_loss: 3.131, enc_ll: -0.04, tp = 29.44 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 40: loss = 86.482, lambda: 50.865, % kept: 1.000, rec_loss: 3.859, enc_ll: -0.04, tp = 29.41 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 42: loss = 768.875, lambda: 51.034, % kept: 0.900, rec_loss: 4.761, enc_ll: -0.32, tp = 29.38 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 44: loss = 30.118, lambda: 51.059, % kept: 1.000, rec_loss: 2.916, enc_ll: -0.04, tp = 29.38 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 46: loss = 54.789, lambda: 51.159, % kept: 1.000, rec_loss: 2.446, enc_ll: -0.04, tp = 29.35 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 48: loss = 55.300, lambda: 51.175, % kept: 1.000, rec_loss: 2.468, enc_ll: -0.04, tp = 29.35 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 50: loss = 19.228, lambda: 51.193, % kept: 1.000, rec_loss: 1.887, enc_ll: -0.04, tp = 29.36 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 52: loss = 91.060, lambda: 51.227, % kept: 1.000, rec_loss: 4.048, enc_ll: -0.04, tp = 29.35 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 54: loss = 19.130, lambda: 51.238, % kept: 1.000, rec_loss: 1.880, enc_ll: -0.04, tp = 29.37 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 56: loss = 483.747, lambda: 51.338, % kept: 0.900, rec_loss: 2.986, enc_ll: -0.32, tp = 29.38 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 58: loss = 54.213, lambda: 51.481, % kept: 1.000, rec_loss: 2.414, enc_ll: -0.04, tp = 29.37 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 60: loss = 26.669, lambda: 51.499, % kept: 1.000, rec_loss: 2.575, enc_ll: -0.04, tp = 29.37 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 62: loss = 59.630, lambda: 51.575, % kept: 1.000, rec_loss: 2.642, enc_ll: -0.04, tp = 29.36 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 64: loss = 19.016, lambda: 51.585, % kept: 1.000, rec_loss: 1.863, enc_ll: -0.04, tp = 29.39 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 66: loss = 76.193, lambda: 51.608, % kept: 1.000, rec_loss: 3.371, enc_ll: -0.04, tp = 29.37 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 68: loss = 32.168, lambda: 51.620, % kept: 1.000, rec_loss: 3.096, enc_ll: -0.04, tp = 29.39 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 70: loss = 17.270, lambda: 51.629, % kept: 1.000, rec_loss: 1.701, enc_ll: -0.04, tp = 29.42 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 72: loss = 18.130, lambda: 51.640, % kept: 1.000, rec_loss: 0.831, enc_ll: -0.04, tp = 29.43 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 74: loss = 40.963, lambda: 51.666, % kept: 1.000, rec_loss: 3.945, enc_ll: -0.04, tp = 29.43 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 76: loss = 25.372, lambda: 51.857, % kept: 1.000, rec_loss: 2.456, enc_ll: -0.04, tp = 29.44 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 78: loss = 211.046, lambda: 51.913, % kept: 0.800, rec_loss: 1.540, enc_ll: -0.54, tp = 29.45 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 80: loss = 294.337, lambda: 52.077, % kept: 0.800, rec_loss: 2.111, enc_ll: -0.54, tp = 29.46 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 82: loss = 14.976, lambda: 52.207, % kept: 1.000, rec_loss: 0.687, enc_ll: -0.04, tp = 29.45 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 84: loss = 29.695, lambda: 52.300, % kept: 1.000, rec_loss: 2.841, enc_ll: -0.04, tp = 29.48 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 86: loss = 138.540, lambda: 52.327, % kept: 0.900, rec_loss: 0.863, enc_ll: -0.32, tp = 29.49 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 88: loss = 756.953, lambda: 52.564, % kept: 0.900, rec_loss: 4.549, enc_ll: -0.32, tp = 29.50 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 90: loss = 22.902, lambda: 52.577, % kept: 1.000, rec_loss: 2.190, enc_ll: -0.04, tp = 29.50 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 92: loss = 22.743, lambda: 52.586, % kept: 1.000, rec_loss: 2.168, enc_ll: -0.04, tp = 29.53 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 94: loss = 86.567, lambda: 52.684, % kept: 1.000, rec_loss: 3.768, enc_ll: -0.04, tp = 29.52 lines/s, ETA 00h00m03s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 iteration 96: loss = 525.296, lambda: 52.799, % kept: 0.900, rec_loss: 3.151, enc_ll: -0.32, tp = 29.50 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 98: loss = 80.287, lambda: 52.820, % kept: 1.000, rec_loss: 3.473, enc_ll: -0.04, tp = 29.49 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 100: loss = 190.872, lambda: 52.894, % kept: 0.800, rec_loss: 1.378, enc_ll: -0.54, tp = 29.51 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 102: loss = 50.256, lambda: 52.910, % kept: 1.000, rec_loss: 2.187, enc_ll: -0.04, tp = 29.50 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 104: loss = 72.039, lambda: 52.931, % kept: 1.000, rec_loss: 3.119, enc_ll: -0.04, tp = 29.51 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 106: loss = 38.413, lambda: 53.037, % kept: 1.000, rec_loss: 3.597, enc_ll: -0.04, tp = 29.51 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 108: loss = 24.639, lambda: 53.135, % kept: 1.000, rec_loss: 2.317, enc_ll: -0.04, tp = 29.52 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 110: loss = 565.962, lambda: 53.366, % kept: 0.800, rec_loss: 3.895, enc_ll: -0.54, tp = 29.53 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 112: loss = 59.097, lambda: 53.384, % kept: 1.000, rec_loss: 2.542, enc_ll: -0.04, tp = 29.54 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 114: loss = 77.292, lambda: 53.409, % kept: 1.000, rec_loss: 3.315, enc_ll: -0.04, tp = 29.53 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 116: loss = 638.904, lambda: 53.530, % kept: 0.900, rec_loss: 3.773, enc_ll: -0.32, tp = 29.53 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 118: loss = 525.362, lambda: 53.637, % kept: 0.900, rec_loss: 3.103, enc_ll: -0.32, tp = 29.52 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 120: loss = 51.297, lambda: 53.656, % kept: 1.000, rec_loss: 2.196, enc_ll: -0.04, tp = 29.50 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 122: loss = 47.719, lambda: 53.676, % kept: 1.000, rec_loss: 2.047, enc_ll: -0.04, tp = 29.49 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 124: loss = 665.405, lambda: 53.809, % kept: 0.900, rec_loss: 3.909, enc_ll: -0.32, tp = 29.47 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 126: loss = 43.062, lambda: 53.834, % kept: 1.000, rec_loss: 3.954, enc_ll: -0.04, tp = 29.47 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 128: loss = 25.635, lambda: 53.851, % kept: 1.000, rec_loss: 2.383, enc_ll: -0.04, tp = 29.47 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 130: loss = 51.897, lambda: 53.865, % kept: 1.000, rec_loss: 2.227, enc_ll: -0.04, tp = 29.48 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 132: loss = 22.106, lambda: 53.879, % kept: 1.000, rec_loss: 2.065, enc_ll: -0.04, tp = 29.48 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 134: loss = 48.925, lambda: 53.893, % kept: 1.000, rec_loss: 2.107, enc_ll: -0.04, tp = 29.49 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 136: loss = 21.875, lambda: 53.990, % kept: 1.000, rec_loss: 2.058, enc_ll: -0.04, tp = 29.52 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 138: loss = 43.417, lambda: 54.079, % kept: 1.000, rec_loss: 1.873, enc_ll: -0.04, tp = 29.50 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 140: loss = 775.366, lambda: 54.227, % kept: 0.800, rec_loss: 2.438, enc_ll: -0.59, tp = 29.51 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 142: loss = 20.781, lambda: 54.238, % kept: 1.000, rec_loss: 1.940, enc_ll: -0.04, tp = 29.53 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 144: loss = 437.599, lambda: 54.330, % kept: 0.800, rec_loss: 2.976, enc_ll: -0.54, tp = 29.53 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 146: loss = 38.813, lambda: 54.457, % kept: 1.000, rec_loss: 3.548, enc_ll: -0.04, tp = 29.53 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 148: loss = 20.844, lambda: 54.465, % kept: 1.000, rec_loss: 1.931, enc_ll: -0.04, tp = 29.54 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 150: loss = 20.786, lambda: 54.482, % kept: 1.000, rec_loss: 1.927, enc_ll: -0.04, tp = 29.55 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 152: loss = 28.410, lambda: 54.545, % kept: 1.000, rec_loss: 1.220, enc_ll: -0.04, tp = 29.54 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 154: loss = 29.588, lambda: 54.756, % kept: 1.000, rec_loss: 2.712, enc_ll: -0.04, tp = 29.54 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 156: loss = 13.343, lambda: 54.762, % kept: 1.000, rec_loss: 1.263, enc_ll: -0.04, tp = 29.56 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 158: loss = 28.744, lambda: 54.777, % kept: 1.000, rec_loss: 1.225, enc_ll: -0.04, tp = 29.54 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 160: loss = 26.612, lambda: 54.849, % kept: 1.000, rec_loss: 2.434, enc_ll: -0.04, tp = 29.57 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 162: loss = 521.456, lambda: 54.955, % kept: 0.800, rec_loss: 3.492, enc_ll: -0.54, tp = 29.57 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 164: loss = 365.318, lambda: 55.150, % kept: 0.800, rec_loss: 2.463, enc_ll: -0.54, tp = 29.58 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 166: loss = 63.668, lambda: 55.180, % kept: 1.000, rec_loss: 2.647, enc_ll: -0.04, tp = 29.56 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 168: loss = 312.400, lambda: 55.297, % kept: 0.800, rec_loss: 2.114, enc_ll: -0.54, tp = 29.59 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 170: loss = 22.825, lambda: 55.306, % kept: 1.000, rec_loss: 0.969, enc_ll: -0.04, tp = 29.59 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 172: loss = 254.540, lambda: 55.356, % kept: 0.800, rec_loss: 1.736, enc_ll: -0.54, tp = 29.61 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 174: loss = 430.610, lambda: 55.440, % kept: 0.900, rec_loss: 2.468, enc_ll: -0.32, tp = 29.61 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 176: loss = 35.859, lambda: 55.508, % kept: 1.000, rec_loss: 3.207, enc_ll: -0.04, tp = 29.62 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 178: loss = 34.855, lambda: 55.519, % kept: 1.000, rec_loss: 3.121, enc_ll: -0.04, tp = 29.64 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 180: loss = 36.661, lambda: 55.531, % kept: 1.000, rec_loss: 3.270, enc_ll: -0.04, tp = 29.66 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 182: loss = 110.043, lambda: 55.625, % kept: 1.000, rec_loss: 4.513, enc_ll: -0.04, tp = 29.66 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 184: loss = 118.854, lambda: 55.653, % kept: 0.800, rec_loss: 0.850, enc_ll: -0.54, tp = 29.67 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 186: loss = 75.005, lambda: 55.672, % kept: 1.000, rec_loss: 3.082, enc_ll: -0.04, tp = 29.67 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 188: loss = 32.715, lambda: 55.685, % kept: 1.000, rec_loss: 2.921, enc_ll: -0.04, tp = 29.68 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 190: loss = 20.355, lambda: 55.705, % kept: 1.000, rec_loss: 1.848, enc_ll: -0.04, tp = 29.69 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 192: loss = 1047.757, lambda: 55.967, % kept: 0.800, rec_loss: 3.193, enc_ll: -0.59, tp = 29.68 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 194: loss = 28.607, lambda: 55.977, % kept: 1.000, rec_loss: 2.548, enc_ll: -0.04, tp = 29.69 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 196: loss = 195.579, lambda: 56.023, % kept: 0.900, rec_loss: 1.129, enc_ll: -0.32, tp = 29.68 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 198: loss = 823.847, lambda: 56.176, % kept: 0.900, rec_loss: 4.631, enc_ll: -0.32, tp = 29.68 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 200: loss = 87.171, lambda: 56.245, % kept: 1.000, rec_loss: 3.542, enc_ll: -0.04, tp = 29.69 lines/s, ETA 00h00m00s\n",
      "Final lambda: 56.2447509765625\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e92900d0bc83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrain_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdumb_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphabet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2788\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m   2789\u001b[0m         is not None else {}), **kwargs)\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1665\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1667\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1903\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_line%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m         \"\"\"\n\u001b[0;32m-> 1924\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \"\"\"\n\u001b[1;32m   1026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0myconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_yorig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'dict'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'learning_rate': 5e-3,\n",
    "    'verbose': True,\n",
    "    'batch_size': 1,\n",
    "    'init_scale': 0.01,\n",
    "    'epochs': 3,\n",
    "    'log_every':2\n",
    "}\n",
    "\n",
    "train_loss_history = train(nencoder, decoder, dumb_dataset, parameters, alphabet, device)\n",
    "plt.plot(train_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 iteration 0: loss = 4.852, tp = 47.03 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 2: loss = 4.851, tp = 42.10 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 4: loss = 4.847, tp = 41.10 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 6: loss = 4.806, tp = 43.31 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 8: loss = 4.763, tp = 41.37 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 10: loss = 4.825, tp = 41.24 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 12: loss = 4.828, tp = 39.99 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 14: loss = 3.933, tp = 40.02 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 16: loss = 4.460, tp = 39.95 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 18: loss = 3.797, tp = 38.74 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 20: loss = 4.012, tp = 38.95 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 22: loss = 2.452, tp = 39.19 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 24: loss = 5.817, tp = 39.36 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 26: loss = 5.833, tp = 38.99 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 28: loss = 3.488, tp = 38.82 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 30: loss = 2.581, tp = 39.09 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 32: loss = 4.205, tp = 39.67 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 34: loss = 3.828, tp = 39.66 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 36: loss = 3.339, tp = 39.60 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 38: loss = 3.145, tp = 40.12 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 40: loss = 4.141, tp = 39.76 lines/s, ETA 00h00m14s\n",
      "Epoch 0 iteration 42: loss = 3.300, tp = 39.84 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 44: loss = 6.613, tp = 40.25 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 46: loss = 4.981, tp = 40.37 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 48: loss = 7.051, tp = 40.69 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 50: loss = 4.573, tp = 40.38 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 52: loss = 3.001, tp = 40.10 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 54: loss = 3.420, tp = 40.15 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 56: loss = 3.622, tp = 40.09 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 58: loss = 2.680, tp = 40.16 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 60: loss = 4.316, tp = 39.80 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 62: loss = 3.077, tp = 39.15 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 64: loss = 2.780, tp = 39.03 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 66: loss = 3.490, tp = 39.09 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 68: loss = 5.967, tp = 39.33 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 70: loss = 4.373, tp = 39.44 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 72: loss = 2.259, tp = 39.48 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 74: loss = 3.823, tp = 39.74 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 76: loss = 3.215, tp = 39.75 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 78: loss = 2.352, tp = 39.90 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 80: loss = 3.158, tp = 39.74 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 82: loss = 3.100, tp = 39.41 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 84: loss = 2.660, tp = 39.47 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 86: loss = 4.150, tp = 39.34 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 88: loss = 3.343, tp = 39.20 lines/s, ETA 00h00m13s\n",
      "Epoch 0 iteration 90: loss = 6.013, tp = 39.37 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 92: loss = 2.668, tp = 39.18 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 94: loss = 8.667, tp = 39.05 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 96: loss = 2.578, tp = 39.08 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 98: loss = 3.897, tp = 39.05 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 100: loss = 2.469, tp = 39.09 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 102: loss = 3.977, tp = 39.31 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 104: loss = 3.769, tp = 39.38 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 106: loss = 2.772, tp = 39.54 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 108: loss = 3.716, tp = 39.33 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 110: loss = 3.920, tp = 39.49 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 112: loss = 3.492, tp = 39.33 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 114: loss = 4.266, tp = 39.20 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 116: loss = 7.050, tp = 39.10 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 118: loss = 4.252, tp = 39.11 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 120: loss = 3.598, tp = 39.13 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 122: loss = 3.460, tp = 39.28 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 124: loss = 2.759, tp = 39.41 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 126: loss = 3.082, tp = 39.29 lines/s, ETA 00h00m12s\n",
      "Epoch 0 iteration 128: loss = 2.623, tp = 39.42 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 130: loss = 2.490, tp = 39.34 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 132: loss = 3.504, tp = 39.36 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 134: loss = 2.395, tp = 39.53 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 136: loss = 2.543, tp = 39.53 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 138: loss = 2.407, tp = 39.55 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 140: loss = 3.874, tp = 39.49 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 142: loss = 2.309, tp = 39.49 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 144: loss = 3.492, tp = 39.39 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 146: loss = 2.722, tp = 39.31 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 148: loss = 3.331, tp = 39.34 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 150: loss = 3.375, tp = 39.48 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 152: loss = 1.712, tp = 39.56 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 154: loss = 4.301, tp = 39.58 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 156: loss = 3.379, tp = 39.44 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 158: loss = 3.912, tp = 39.37 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 160: loss = 2.869, tp = 39.40 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 162: loss = 3.421, tp = 39.40 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 164: loss = 3.599, tp = 39.41 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 166: loss = 3.402, tp = 39.35 lines/s, ETA 00h00m11s\n",
      "Epoch 0 iteration 168: loss = 2.222, tp = 39.35 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 170: loss = 2.425, tp = 39.35 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 172: loss = 1.710, tp = 39.28 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 174: loss = 3.110, tp = 39.28 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 176: loss = 2.273, tp = 39.28 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 178: loss = 2.215, tp = 39.31 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 180: loss = 3.364, tp = 39.32 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 182: loss = 2.501, tp = 39.43 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 184: loss = 1.645, tp = 39.44 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 186: loss = 3.016, tp = 39.54 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 188: loss = 3.103, tp = 39.47 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 190: loss = 3.156, tp = 39.57 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 192: loss = 1.973, tp = 39.58 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 194: loss = 3.034, tp = 39.60 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 196: loss = 0.935, tp = 39.45 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 198: loss = 2.953, tp = 39.54 lines/s, ETA 00h00m10s\n",
      "Epoch 0 iteration 200: loss = 2.510, tp = 39.54 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 1: loss = 4.133, tp = 39.57 lines/s, ETA 00h00m10s\n",
      "Epoch 1 iteration 3: loss = 3.092, tp = 39.54 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 5: loss = 3.591, tp = 39.58 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 7: loss = 2.893, tp = 39.65 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 9: loss = 3.363, tp = 39.61 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 11: loss = 2.461, tp = 39.53 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 13: loss = 1.909, tp = 39.51 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 15: loss = 3.193, tp = 39.44 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 17: loss = 2.425, tp = 39.46 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 19: loss = 2.856, tp = 39.54 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 21: loss = 0.975, tp = 39.55 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 23: loss = 2.035, tp = 39.51 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 25: loss = 1.934, tp = 39.42 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 27: loss = 3.227, tp = 39.29 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 29: loss = 1.945, tp = 39.33 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 31: loss = 1.499, tp = 39.34 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 33: loss = 1.568, tp = 39.30 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 35: loss = 2.832, tp = 39.23 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 37: loss = 2.533, tp = 39.24 lines/s, ETA 00h00m09s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 iteration 39: loss = 2.781, tp = 39.23 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 41: loss = 1.966, tp = 39.23 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 43: loss = 1.521, tp = 39.19 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 45: loss = 2.123, tp = 39.16 lines/s, ETA 00h00m09s\n",
      "Epoch 1 iteration 47: loss = 3.590, tp = 39.15 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 49: loss = 2.953, tp = 39.17 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 51: loss = 1.237, tp = 39.22 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 53: loss = 4.973, tp = 39.23 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 55: loss = 2.356, tp = 39.18 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 57: loss = 2.112, tp = 39.17 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 59: loss = 3.329, tp = 39.12 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 61: loss = 2.304, tp = 39.18 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 63: loss = 1.706, tp = 39.19 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 65: loss = 2.460, tp = 39.17 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 67: loss = 1.125, tp = 39.14 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 69: loss = 3.876, tp = 39.14 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 71: loss = 2.941, tp = 39.12 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 73: loss = 3.453, tp = 39.07 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 75: loss = 3.079, tp = 39.14 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 77: loss = 1.285, tp = 39.16 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 79: loss = 4.763, tp = 39.12 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 81: loss = 3.628, tp = 39.16 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 83: loss = 4.089, tp = 39.18 lines/s, ETA 00h00m08s\n",
      "Epoch 1 iteration 85: loss = 1.341, tp = 39.24 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 87: loss = 2.240, tp = 39.20 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 89: loss = 2.506, tp = 39.25 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 91: loss = 2.044, tp = 39.26 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 93: loss = 3.347, tp = 39.25 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 95: loss = 2.247, tp = 39.27 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 97: loss = 0.478, tp = 39.28 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 99: loss = 5.342, tp = 39.29 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 101: loss = 2.893, tp = 39.36 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 103: loss = 2.608, tp = 39.35 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 105: loss = 1.664, tp = 39.37 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 107: loss = 3.703, tp = 39.29 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 109: loss = 2.531, tp = 39.31 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 111: loss = 2.304, tp = 39.30 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 113: loss = 2.018, tp = 39.24 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 115: loss = 3.024, tp = 39.22 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 117: loss = 3.309, tp = 39.16 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 119: loss = 0.840, tp = 39.12 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 121: loss = 1.756, tp = 39.15 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 123: loss = 3.441, tp = 39.11 lines/s, ETA 00h00m07s\n",
      "Epoch 1 iteration 125: loss = 2.045, tp = 39.16 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 127: loss = 1.374, tp = 39.18 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 129: loss = 2.875, tp = 39.22 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 131: loss = 2.683, tp = 39.20 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 133: loss = 1.967, tp = 39.16 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 135: loss = 2.167, tp = 39.17 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 137: loss = 2.788, tp = 39.19 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 139: loss = 2.695, tp = 39.15 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 141: loss = 0.991, tp = 39.16 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 143: loss = 2.258, tp = 39.14 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 145: loss = 2.428, tp = 39.15 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 147: loss = 1.395, tp = 39.15 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 149: loss = 2.309, tp = 39.10 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 151: loss = 1.095, tp = 39.10 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 153: loss = 1.827, tp = 39.03 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 155: loss = 0.931, tp = 39.06 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 157: loss = 2.392, tp = 39.06 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 159: loss = 3.372, tp = 39.09 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 161: loss = 2.159, tp = 39.09 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 163: loss = 2.124, tp = 39.07 lines/s, ETA 00h00m06s\n",
      "Epoch 1 iteration 165: loss = 3.749, tp = 39.06 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 167: loss = 3.320, tp = 39.09 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 169: loss = 3.193, tp = 39.11 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 171: loss = 3.053, tp = 39.07 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 173: loss = 2.977, tp = 39.07 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 175: loss = 2.800, tp = 39.06 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 177: loss = 3.108, tp = 39.10 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 179: loss = 0.880, tp = 39.16 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 181: loss = 1.265, tp = 39.16 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 183: loss = 1.645, tp = 39.16 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 185: loss = 3.602, tp = 39.21 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 187: loss = 1.718, tp = 39.22 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 189: loss = 0.935, tp = 39.15 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 191: loss = 1.055, tp = 39.18 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 193: loss = 2.796, tp = 39.23 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 195: loss = 1.955, tp = 39.19 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 197: loss = 0.836, tp = 39.23 lines/s, ETA 00h00m05s\n",
      "Epoch 1 iteration 199: loss = 2.848, tp = 39.20 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 0: loss = 4.611, tp = 39.19 lines/s, ETA 00h00m05s\n",
      "Epoch 2 iteration 2: loss = 2.716, tp = 39.14 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 4: loss = 2.905, tp = 39.18 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 6: loss = 1.890, tp = 39.15 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 8: loss = 0.459, tp = 39.17 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 10: loss = 2.799, tp = 39.13 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 12: loss = 4.419, tp = 39.12 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 14: loss = 0.904, tp = 39.15 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 16: loss = 1.432, tp = 39.19 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 18: loss = 2.706, tp = 39.18 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 20: loss = 2.910, tp = 39.22 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 22: loss = 0.710, tp = 39.25 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 24: loss = 2.894, tp = 39.24 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 26: loss = 0.561, tp = 39.26 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 28: loss = 1.050, tp = 39.21 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 30: loss = 3.649, tp = 39.23 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 32: loss = 2.031, tp = 39.24 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 34: loss = 2.963, tp = 39.23 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 36: loss = 0.362, tp = 39.21 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 38: loss = 1.243, tp = 39.25 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 40: loss = 0.560, tp = 39.21 lines/s, ETA 00h00m04s\n",
      "Epoch 2 iteration 42: loss = 2.654, tp = 39.22 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 44: loss = 3.630, tp = 39.25 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 46: loss = 2.753, tp = 39.25 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 48: loss = 1.720, tp = 39.24 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 50: loss = 0.764, tp = 39.26 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 52: loss = 2.162, tp = 39.22 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 54: loss = 2.745, tp = 39.26 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 56: loss = 2.420, tp = 39.20 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 58: loss = 1.893, tp = 39.19 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 60: loss = 2.677, tp = 39.16 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 62: loss = 1.073, tp = 39.18 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 64: loss = 0.940, tp = 39.16 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 66: loss = 1.807, tp = 39.15 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 68: loss = 1.984, tp = 39.15 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 70: loss = 1.214, tp = 39.16 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 72: loss = 3.451, tp = 39.14 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 74: loss = 2.822, tp = 39.18 lines/s, ETA 00h00m03s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 iteration 76: loss = 0.929, tp = 39.16 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 78: loss = 2.466, tp = 39.13 lines/s, ETA 00h00m03s\n",
      "Epoch 2 iteration 80: loss = 2.629, tp = 39.10 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 82: loss = 0.959, tp = 39.07 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 84: loss = 0.852, tp = 39.09 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 86: loss = 0.992, tp = 39.09 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 88: loss = 0.858, tp = 39.13 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 90: loss = 2.245, tp = 39.11 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 92: loss = 2.008, tp = 39.13 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 94: loss = 3.633, tp = 39.10 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 96: loss = 1.380, tp = 39.15 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 98: loss = 0.903, tp = 39.14 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 100: loss = 2.375, tp = 39.14 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 102: loss = 2.671, tp = 39.15 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 104: loss = 0.761, tp = 39.15 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 106: loss = 1.813, tp = 39.11 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 108: loss = 0.616, tp = 39.08 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 110: loss = 0.846, tp = 39.09 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 112: loss = 1.796, tp = 39.07 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 114: loss = 0.637, tp = 39.09 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 116: loss = 0.949, tp = 39.08 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 118: loss = 2.482, tp = 39.12 lines/s, ETA 00h00m02s\n",
      "Epoch 2 iteration 120: loss = 2.118, tp = 39.09 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 122: loss = 2.210, tp = 39.04 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 124: loss = 3.084, tp = 39.00 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 126: loss = 0.681, tp = 38.95 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 128: loss = 1.213, tp = 38.91 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 130: loss = 2.315, tp = 38.92 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 132: loss = 2.753, tp = 38.91 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 134: loss = 0.893, tp = 38.90 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 136: loss = 3.157, tp = 38.91 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 138: loss = 0.938, tp = 38.89 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 140: loss = 2.593, tp = 38.84 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 142: loss = 1.333, tp = 38.83 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 144: loss = 0.698, tp = 38.87 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 146: loss = 1.274, tp = 38.89 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 148: loss = 1.950, tp = 38.87 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 150: loss = 3.157, tp = 38.88 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 152: loss = 0.751, tp = 38.87 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 154: loss = 1.997, tp = 38.85 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 156: loss = 0.488, tp = 38.83 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 158: loss = 1.261, tp = 38.85 lines/s, ETA 00h00m01s\n",
      "Epoch 2 iteration 160: loss = 2.370, tp = 38.86 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 162: loss = 1.569, tp = 38.85 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 164: loss = 0.760, tp = 38.89 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 166: loss = 0.832, tp = 38.89 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 168: loss = 2.032, tp = 38.87 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 170: loss = 1.966, tp = 38.85 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 172: loss = 0.641, tp = 38.86 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 174: loss = 3.332, tp = 38.86 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 176: loss = 2.111, tp = 38.84 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 178: loss = 0.722, tp = 38.77 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 180: loss = 1.366, tp = 38.78 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 182: loss = 2.189, tp = 38.78 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 184: loss = 1.505, tp = 38.78 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 186: loss = 1.947, tp = 38.76 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 188: loss = 1.843, tp = 38.76 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 190: loss = 0.544, tp = 38.76 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 192: loss = 1.115, tp = 38.77 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 194: loss = 2.731, tp = 38.80 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 196: loss = 1.586, tp = 38.79 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 198: loss = 0.927, tp = 38.82 lines/s, ETA 00h00m00s\n",
      "Epoch 2 iteration 200: loss = 0.647, tp = 38.85 lines/s, ETA 00h00m00s\n"
     ]
    }
   ],
   "source": [
    "encoder = UniformEncoder(removal_probability=.8)\n",
    "train_loss_history = train(encoder, decoder, dumb_dataset, parameters, alphabet, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\x01eee\\x02', '\\x01eke\\x02', '\\x01ek\\x02', '\\x01ee\\x02', '\\x01ke\\x02']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x:x[1], decoder.beam_search(\"hello\", alphabet, beam_size=5, max_depth=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "tensor([0., 0.], grad_fn=<BernoulliBackward0>)\n",
      "None\n",
      "tensor(-0.3185, grad_fn=<SqueezeBackward1>)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ps = torch.tensor([0.3, 0.8], requires_grad=True)\n",
    "bs = torch.bernoulli(ps)\n",
    "s = bs.sum()\n",
    "print(s)\n",
    "s.backward()\n",
    "print(bs)\n",
    "print(bs.grad)\n",
    "\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "b = Categorical(ps)\n",
    "mask = b.sample()\n",
    "# next_state, reward = env.step(action)\n",
    "# loss = -m.log_prob(action) * reward\n",
    "loss = b.log_prob(mask)\n",
    "loss.backward()\n",
    "print(loss)\n",
    "print(mask.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs._grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String: 'ooooo'\n",
      "Encoded: 'ooo'\n",
      "Decoded: 'eee'\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "SPLIT = 'train'\n",
    "\n",
    "import copy\n",
    "\n",
    "s = random.choice(dumb_dataset[SPLIT])\n",
    "compressed = encoder.encode(s)\n",
    "decompressed = decoder([compressed],alphabet)\n",
    "\n",
    "print('String:', repr(s))\n",
    "print('Encoded:', repr(compressed))\n",
    "print('Decoded:', repr(decompressed[0]))\n",
    "print(len(decompressed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def average(x): return sum(x)/len(x)\n",
    "\n",
    "def edit_distance(s1,s2):\n",
    "    if len(s1)==0: return len(s2)\n",
    "    if len(s2)==0: return len(s1)\n",
    "    if s1[0] == s2[0]: return edit_distance(s1[1:], s2[1:])\n",
    "    return 1 + min(edit_distance(s1[1:],s2),\n",
    "                   edit_distance(s1,s2[1:]),\n",
    "                   edit_distance(s1[1:],s2[1:]))\n",
    "print(edit_distance('goose','geese'))\n",
    "print(edit_distance('geek','gesek'))\n",
    "print(edit_distance('cat','cut'))\n",
    "print(edit_distance('saturday','sunday'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.055\n",
      "0.185\n"
     ]
    }
   ],
   "source": [
    "def top1accuracy(dataset):\n",
    "    return len(list(filter(lambda s: s == decoder([encoder.encode(s)],alphabet)[0],\n",
    "                         dataset)))/len(dataset)\n",
    "\n",
    "def top5accuracy(dataset):\n",
    "    count = 0\n",
    "    for string in dataset:\n",
    "        compressed = encoder.encode(string)\n",
    "        best_five = list(map(lambda x:x[1][1:-1], \n",
    "                             decoder.beam_search(compressed, alphabet, beam_size=5, max_depth=20)))\n",
    "        if string in best_five: count += 1\n",
    "    return float(count) / len(dataset)\n",
    "\n",
    "def editAccuracy(dataset):\n",
    "    return average([\n",
    "        edit_distance(decoder(encoder.encode(s), alphabet), \n",
    "                      s)/len(s) for s in dataset])\n",
    "\n",
    "print(top1accuracy(dumb_dataset[SPLIT]))\n",
    "print(top5accuracy(dumb_dataset[SPLIT]))\n",
    "print(editAccuracy(dumb_dataset[SPLIT]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
